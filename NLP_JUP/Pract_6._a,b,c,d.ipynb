{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc967c13-f65b-4d88-b21c-684e5d93fff3",
   "metadata": {},
   "source": [
    "**6a) Define grammar using nltk. Analyze a sentence using the same**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f69d3848-e6f2-414a-9817-2d856a6de234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP Bob)))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import RecursiveDescentParser\n",
    "grammer = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "VP -> V NP | V NP PP\n",
    "PP -> P NP\n",
    "V -> \"saw\" \n",
    "NP ->\"Mary\" | \"Bob\" | Det N \n",
    "Det -> \"a\" | \"an\" | \"the\"\n",
    "N -> \"man\" | \"dog\" | \"cat\"\n",
    "P -> \"in\" | \"on\"\n",
    "\"\"\")\n",
    "\n",
    "sent = \"Mary saw Bob\".split()\n",
    "rd_parser = nltk.RecursiveDescentParser(grammer)\n",
    "for tree in rd_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e4d3f7-e234-4950-ae7a-d78bff1aae63",
   "metadata": {},
   "source": [
    "**Using ChartParser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "328c1956-3f0f-4e6d-846e-c7397d4b6597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token:  ['Book', 'that', 'flight']\n",
      "(S (VP (VP Book) (NP (Det that) (NP flight))))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\prath\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import tokenize\n",
    "\n",
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "S -> VP\n",
    "VP -> VP NP\n",
    "NP -> Det NP\n",
    "Det -> 'that'\n",
    "NP -> 'flight'\n",
    "VP -> 'Book'\n",
    "\"\"\")\n",
    "\n",
    "sentence = \"Book that flight\"\n",
    "\n",
    "for index in range(len(sentence)):\n",
    "  all_tokens = tokenize.word_tokenize(sentence)\n",
    "print(\"Token: \",all_tokens)\n",
    "parser = nltk.ChartParser(grammar1)\n",
    "for tree in parser.parse(all_tokens):\n",
    "  print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17264d74-a34b-4dd2-87f0-180d1ce68b92",
   "metadata": {},
   "source": [
    "**7b) Accept the input string with Regular expression of Finite Automaton: 101+.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68adf362-d9f0-40d8-9f24-03f3c181861a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 1 - Rejected\n",
      "Input: 10101 - Rejected\n",
      "Input: 101 - Accepted\n",
      "Input: 10111 - Accepted\n",
      "Input: 01010 - Rejected\n",
      "Input: 100 - Rejected\n",
      "Input:  - Rejected\n",
      "Input: 10111101 - Rejected\n",
      "Input: 1011111 - Accepted\n"
     ]
    }
   ],
   "source": [
    "def FA(s):\n",
    "    if len(s) < 3:\n",
    "        return \"Rejected\"\n",
    "        \n",
    "    if s[0] == '1':  \n",
    "        if s[1] == '0': \n",
    "            if s[2] == '1':  \n",
    "                \n",
    "                for i in range(3, len(s)):  \n",
    "                    if s[i] != '1':  # If any character is not '1'\n",
    "                        return \"Rejected\"  \n",
    "                return \"Accepted\"\n",
    "    \n",
    "\n",
    "    return \"Rejected\"\n",
    "\n",
    "inputs = ['1', '10101', '101', '10111', '01010', '100', '', '10111101', '1011111']\n",
    "\n",
    "for i in inputs:\n",
    "    print(f\"Input: {i} - {FA(i)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7931ac0e-a05b-455f-b155-a8c342ec6a25",
   "metadata": {},
   "source": [
    "**7c) Accept the input string with Regular expression of FA: (a+b) * bba.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7864db-cfdf-4330-b8c7-047d7c78d089",
   "metadata": {},
   "source": [
    "The regular expression (a+b)*bba can be broken down as follows:\r\n",
    "\r\n",
    "(a+b)*: Zero or more occurrences of either 'a' or 'b'. bba: The string must end with the sequence 'bba'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cc957ac-0039-4bb3-97be-79d153fab253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: bba - Accepted\n",
      "Input: ababbba - Accepted\n",
      "Input: abba - Accepted\n",
      "Input: abb - Rejected\n",
      "Input: baba - Rejected\n",
      "Input: bbb - Rejected\n",
      "Input:  - Rejected\n"
     ]
    }
   ],
   "source": [
    "def FA(s):\n",
    "    size = 0\n",
    "    # Scan the complete string and make sure that it contains only 'a' & 'b'\n",
    "    for i in s:\n",
    "        if i == 'a' or i == 'b':\n",
    "            size += 1\n",
    "        else:\n",
    "            return \"Rejected\"\n",
    "\n",
    "    if size >= 3:\n",
    "        if s[size-3] == 'b':\n",
    "            if s[size-2] == 'b':\n",
    "                if s[size-1] == 'a':\n",
    "                    return \"Accepted\"\n",
    "                return \"Rejected\" \n",
    "            return \"Rejected\" \n",
    "        return \"Rejected\" \n",
    "    return \"Rejected\" \n",
    "\n",
    "inputs = ['bba', 'ababbba', 'abba', 'abb', 'baba', 'bbb', '']\n",
    "\n",
    "for i in inputs:\n",
    "    print(f\"Input: {i} - {FA(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786d30d6-7474-4e45-9f1f-efb686983365",
   "metadata": {},
   "source": [
    "# 7d) Implementation of Deductive Chart Parsing using context free grammar and a given sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ca7b706-3a4c-4869-99a4-92c1fe9336a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'saw', 'a', 'bird', 'in', 'my', 'balcony']\n",
      "Chart Parser\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V saw) (NP (Det a) (N bird)))\n",
      "    (PP (P in) (NP (Det my) (N balcony)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det a) (N bird) (PP (P in) (NP (Det my) (N balcony))))))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import CFG, ChartParser\n",
    "from nltk import word_tokenize\n",
    "\n",
    "grammar1 = CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det N PP | 'I'\n",
    "VP -> V NP | VP PP\n",
    "Det -> 'a' | 'my'\n",
    "N -> 'bird' | 'balcony'\n",
    "V -> 'saw'\n",
    "P -> 'in'\n",
    "\"\"\")\n",
    "\n",
    "sentence = \"I saw a bird in my balcony\"\n",
    "all_tokens = word_tokenize(sentence)\n",
    "print(all_tokens)\n",
    "\n",
    "print(\"Chart Parser\")\n",
    "parser = ChartParser(grammar1)\n",
    "\n",
    "for tree in parser.parse(all_tokens):\n",
    "    print(tree)\n",
    "    tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b74c0d-5ef9-4b39-bc2c-6037c6c62fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
