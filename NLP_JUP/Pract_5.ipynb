{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "837c206c-a78b-45a7-ae59-b2be70f816f2",
   "metadata": {},
   "source": [
    "**Aim: Illustrate part of speech tagging.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f0e3fb-7ae1-4bf1-b495-31b7c5c2502c",
   "metadata": {},
   "source": [
    "**a. Part of speech Tagging and chunking of user defined text.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a40c93-a4bd-49c3-991c-dcded0c7f29c",
   "metadata": {},
   "source": [
    "``example:\r\n",
    "Input: Everything to permit us.\r\n",
    "Output: [('Everything', NN),('to', TO), ('permit', VB), ('us', PRP)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ff58f3d-3ea8-43c9-83c7-71e7e9a23db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n",
      "After Split: ['Everything', 'to', 'permit', 'us.']\n",
      "After Token: [('Everything', 'NN'), ('to', 'TO'), ('permit', 'VB'), ('us.', 'JJ')]\n",
      "After Regex: chunk.RegexpParser with 1 stages:\n",
      "RegexpChunkParser with 1 rules:\n",
      "       <ChunkRule: '<NN.?>*<VBD.?>*<JJ.?>*<CC>?'>\n",
      "After Chunking (S (mychunk Everything/NN) to/TO permit/VB (mychunk us./JJ))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\prath\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk import RegexpParser\n",
    "nltk.download()\n",
    "\n",
    "text =\"Everything to permit us.\".split()\n",
    "print(\"After Split:\",text)\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "tokens_tag = pos_tag(text)\n",
    "print(\"After Token:\",tokens_tag)\n",
    "\n",
    "patterns= \"\"\"mychunk:{<NN.?>*<VBD.?>*<JJ.?>*<CC>?}\"\"\"\n",
    "chunker = RegexpParser(patterns)\n",
    "print(\"After Regex:\",chunker)\n",
    "output = chunker.parse(tokens_tag)\n",
    "print(\"After Chunking\",output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ff154f-a8c6-4df5-89b1-97a070eeb881",
   "metadata": {},
   "source": [
    "**b. Named Entity recognition of user defined text.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d85f2ea0-4806-47d3-adb9-d74de093aa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('India', 'GPE'), ('Microsoft', 'ORG'), ('$200 billion', 'MONEY'), ('Monday', 'DATE')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "\n",
    "ex = 'India fined Microsoft a  $200 billion on Monday'\n",
    "\n",
    "ex = nlp('India fined Microsoft a  $200 billion on Monday')\n",
    "\n",
    "print([(X.text, X.label_) for X in ex.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b312d18-7d33-4c49-98b7-8ed6b1c5ac59",
   "metadata": {},
   "source": [
    "**c. Named Entity recognition with diagram using NLTK corpus â€“ treebank**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "285f26bb-eb2a-476d-8b63-d0ce50035529",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\prath\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\prath\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\prath\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\prath\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NE tagged text:\n",
      "(S\n",
      "  (GPE Newton/NNP)\n",
      "  first/RB\n",
      "  suggested/VBD\n",
      "  the/DT\n",
      "  name/NN\n",
      "  ``/``\n",
      "  apple/NN\n",
      "  gravity/NN\n",
      "  ''/''\n",
      "  at/IN\n",
      "  (ORGANIZATION New/NNP Town/NNP)\n",
      "  ,/,\n",
      "  (GPE America/NNP))\n",
      "\n",
      "Recognized named entities:\n",
      "GPE [('Newton', 'NNP')]\n",
      "ORGANIZATION [('New', 'NNP'), ('Town', 'NNP')]\n",
      "GPE [('America', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "sentence = 'Newton first suggested the name \"apple gravity\" at New Town, America'\n",
    "words = nltk.word_tokenize(sentence)\n",
    "pos_tagged = nltk.pos_tag(words)\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "ne_tagged = nltk.ne_chunk(pos_tagged)\n",
    "print(\"NE tagged text:\")\n",
    "print(ne_tagged)\n",
    "print()\n",
    "print(\"Recognized named entities:\")\n",
    "for ne in ne_tagged:\n",
    "    if hasattr(ne, \"label\"):\n",
    "        print(ne.label(), ne[0:])\n",
    "        ne_tagged.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b203db61-dd91-41b1-b184-b1939c061df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
